# pocket-narrator : Efficient Story Generation with Mamba

> **Master Project: Efficient Methods in Machine Learning** > *Exploring the capabilities of Small Language Models (SLMs) on the TinyStories dataset.*

## ðŸ“– Overview
This repository contains an end-to-end implementation of the **Mamba** state-space model architecture designed for efficient language modeling. The project investigates how well small Mamba models can learn to generate coherent English stories when trained on the **TinyStories** dataset.

## Repository Structure: 

pocket-narrator/
â”œâ”€â”€ configs/                          # Configuration files (YAML)
â”‚   â”œâ”€â”€ mamba_tinystories_2k/
â”‚   â”‚   â”œâ”€â”€ model.yaml
â”‚   â”‚   â”œâ”€â”€ tokenizer.yaml
â”‚   â”‚   â””â”€â”€ training.yaml
â”‚   â”œâ”€â”€ mamba_tinystories_1M/
â”‚   â”‚   â”œâ”€â”€ model.yaml
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ train_tokenizer_and_lm_dataset.yaml
â”œâ”€â”€ pocket_narrator/                  # Source code package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ mamba/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ config_utils.py       # YAML loading utilities
â”‚           â”œâ”€â”€ mamba_evaluation.py   # PPL calculation & metrics
â”‚           â”œâ”€â”€ mamba_generate.py     # Story generation script
â”‚           â”œâ”€â”€ mamba_main.py         # Main training entry point
â”‚           â”œâ”€â”€ mamba_model.py        # Mamba architecture definition
â”‚           â”œâ”€â”€ mamba_trainer.py      # Training loop & logic
â”‚           â””â”€â”€ train_tokenizer_and_lm_dataset.py # Data preprocessing
â”œâ”€â”€ results/                          # Checkpoints (add to .gitignore)
â”œâ”€â”€ tokenizers/                       # Saved tokenizers (add to .gitignore)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

